{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age        Debt  YearsEmployed  CreditScore      ZipCode  \\\n",
      "count  678.000000  690.000000     690.000000    690.00000   677.000000   \n",
      "mean    31.568171    4.758725       2.223406      2.40000   184.014771   \n",
      "std     11.957862    4.978163       3.346513      4.86294   173.806768   \n",
      "min     13.750000    0.000000       0.000000      0.00000     0.000000   \n",
      "25%     22.602500    1.000000       0.165000      0.00000    75.000000   \n",
      "50%     28.460000    2.750000       1.000000      0.00000   160.000000   \n",
      "75%     38.230000    7.207500       2.625000      3.00000   276.000000   \n",
      "max     80.250000   28.000000      28.500000     67.00000  2000.000000   \n",
      "\n",
      "              Income  \n",
      "count     690.000000  \n",
      "mean     1017.385507  \n",
      "std      5210.102598  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         5.000000  \n",
      "75%       395.500000  \n",
      "max    100000.000000  \n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "credit_data = pd.read_csv('C:\\credit-approval_csv.csv')\n",
    "#Looking at the dataset\n",
    "credit_data.head()\n",
    "#\n",
    "credit_description = credit_data.describe()\n",
    "print(credit_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Gender           678 non-null    object \n",
      " 1   Age              678 non-null    float64\n",
      " 2   Debt             690 non-null    float64\n",
      " 3   Married          684 non-null    object \n",
      " 4   BankCustomer     684 non-null    object \n",
      " 5   EducationLevel   681 non-null    object \n",
      " 6   Ethnicity        681 non-null    object \n",
      " 7   YearsEmployed    690 non-null    float64\n",
      " 8   PriorDefault     690 non-null    object \n",
      " 9   Employed         690 non-null    object \n",
      " 10  CreditScore      690 non-null    int64  \n",
      " 11  DriversLicense   690 non-null    object \n",
      " 12  Citizen          690 non-null    object \n",
      " 13  ZipCode          677 non-null    float64\n",
      " 14  Income           690 non-null    int64  \n",
      " 15  Approved         690 non-null    object \n",
      " 16  Approved_Status  690 non-null    object \n",
      "dtypes: float64(4), int64(2), object(11)\n",
      "memory usage: 91.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "credit_info = credit_data.info()\n",
    "print(credit_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender             12\n",
      "Age                 0\n",
      "Debt                0\n",
      "Married             6\n",
      "BankCustomer        6\n",
      "EducationLevel      9\n",
      "Ethnicity           9\n",
      "YearsEmployed       0\n",
      "PriorDefault        0\n",
      "Employed            0\n",
      "CreditScore         0\n",
      "DriversLicense      0\n",
      "Citizen             0\n",
      "ZipCode             0\n",
      "Income              0\n",
      "Approved            0\n",
      "Approved_Status     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace \"?\" with NaN\n",
    "credit_data.replace('?', np.NaN, inplace = True)\n",
    "#Replacing the misssing value by mean value\n",
    "credit_data.fillna(credit_data.mean(), inplace=True)\n",
    "# Convert Age to numeric\n",
    "credit_data[\"Age\"] = pd.to_numeric(credit_data[\"Age\"])\n",
    "print(credit_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender             0\n",
      "Age                0\n",
      "Debt               0\n",
      "Married            0\n",
      "BankCustomer       0\n",
      "EducationLevel     0\n",
      "Ethnicity          0\n",
      "YearsEmployed      0\n",
      "PriorDefault       0\n",
      "Employed           0\n",
      "CreditScore        0\n",
      "DriversLicense     0\n",
      "Citizen            0\n",
      "ZipCode            0\n",
      "Income             0\n",
      "Approved           0\n",
      "Approved_Status    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in credit_data.columns:\n",
    "    # Check if the column is of object type\n",
    "    if credit_data[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        credit_data = credit_data.fillna(credit_data[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "print(credit_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in credit_data.columns.values:\n",
    "    # Compare if the dtype is object\n",
    "    if credit_data[col].dtypes=='object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        credit_data[col]=le.fit_transform(credit_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
    "credit_data = credit_data.drop(['DriversLicense', 'ZipCode'], axis=1)\n",
    "credit_data = credit_data.values\n",
    "\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X,y = credit_data[:,0:13] , credit_data[:,13]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    ,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  0.8421052631578947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[94,  9],\n",
       "       [27, 98]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01, 0.001 ,0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.850725 using {'max_iter': 100, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Use scaler to rescale X and assign it to rescaledX\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# Fit grid_model to the data\n",
    "grid_model_result = grid_model.fit(rescaledX, y)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
